import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

st.title("ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø© Ø°ÙƒÙŠ ğŸ¤–")
st.write("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ ÙˆØ³ÙˆÙ ÙŠØ¬ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")
    model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")
    generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
    return generator

generator = load_model()

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_input = st.text_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:")

if st.button("Ø£Ø±Ø³Ù„"):
    if user_input.strip() != "":
        with st.spinner("Ø¬Ø§Ø±Ù ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø±Ø¯..."):
            response = generator(user_input, max_length=100, do_sample=True, top_k=50, top_p=0.95)
            st.success(response[0]['generated_text'])
    else:
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø£Ø±Ø³Ù„!")
